{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas pyarrow deep-translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Instanciar o tradutor\n",
    "translator = GoogleTranslator(source= \"fr\", target= \"en\")\n",
    "\n",
    "# Configuração do logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para salvar os dados brutos na pasta raw_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_raw_data(name, raw_path, api_url):\n",
    "    try:\n",
    "        # Fazer a chamada na API\n",
    "        response = requests.get(api_url)        \n",
    "        # Verificar se a requisição foi bem-sucedida\n",
    "        response.raise_for_status()  # Levanta um erro se o status não for 2xx\n",
    "        # Verificar se o conteúdo é JSON\n",
    "        if response.headers['Content-Type'].startswith('application/json'):\n",
    "            data = response.json()            \n",
    "            # Verificar se os dados retornados possuem a estrutura esperada\n",
    "            if isinstance(data, list):\n",
    "                df = pd.DataFrame(data)                \n",
    "                # Verificar se o diretório de destino existe, caso contrário, criar\n",
    "                os.makedirs(os.path.dirname(raw_path), exist_ok=True)                \n",
    "                # Salvar os dados no formato Parquet\n",
    "                df.to_parquet(raw_path, engine=\"pyarrow\", index=False)\n",
    "                logging.info(f\"Arquivo '{raw_path}' criado/sobrescrito com sucesso.\")\n",
    "            else:\n",
    "                logging.error(f\"A resposta da API de {name} não contém uma lista de dados.\")\n",
    "        else:\n",
    "            logging.error(f\"A resposta da API de {name} não contém um JSON válido.\")    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Erro na requisição (ex.: erro de rede, timeout, etc.)\n",
    "        logging.error(f\"Erro na chamada da API de {name}: {e}\")    \n",
    "    except Exception as e:\n",
    "        # Outros erros (ex.: erro ao salvar o arquivo, erro ao processar os dados)\n",
    "        logging.error(f\"Ocorreu um erro ao processar os dados de {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para salvar os dados filtrados na pasta filtered_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nested_field(field, key, default=None):\n",
    "    if isinstance(field, dict) and key in field:\n",
    "        return field[key]\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_characters_data(raw_path, filtered_path):\n",
    "    try:\n",
    "        # Ler o arquivo Parquet\n",
    "        df_characters = pd.read_parquet(raw_path, engine='pyarrow')\n",
    "        # Verificar se o DataFrame tem dados\n",
    "        if df_characters.empty:\n",
    "            raise ValueError(\"O arquivo Parquet não contém dados.\")\n",
    "        # Criar um novo DataFrame com as colunas desejadas\n",
    "        df_filtered = pd.DataFrame({\n",
    "            'id': df_characters['id'],\n",
    "            'name': df_characters['name'],\n",
    "            'size': df_characters['size'],\n",
    "            'age': df_characters['age'],\n",
    "            'bounty': df_characters['bounty'],\n",
    "            'crew_id': df_characters['crew'].apply(lambda x: extract_nested_field(x, 'id')),\n",
    "            'fruit_id': df_characters['fruit'].apply(lambda x: extract_nested_field(x, 'id')),\n",
    "            'job': df_characters['job'],\n",
    "            'status': df_characters['status']\n",
    "        })\n",
    "        # Verificar e criar o diretório de saída se necessário\n",
    "        os.makedirs(os.path.dirname(filtered_path), exist_ok=True)\n",
    "        # Salvar o DataFrame filtrado em Parquet\n",
    "        df_filtered.to_parquet(filtered_path, engine=\"pyarrow\", index=False)\n",
    "        logging.info(f\"Arquivo salvo com sucesso em '{filtered_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar os dados: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fruits_data(raw_path, filtered_path):\n",
    "    try:\n",
    "        # Ler o arquivo Parquet\n",
    "        df_fruits = pd.read_parquet(raw_path, engine='pyarrow')\n",
    "        # Verificar se o DataFrame tem dados\n",
    "        if df_fruits.empty:\n",
    "            raise ValueError(\"O arquivo Parquet não contém dados.\")\n",
    "        # Criar um novo DataFrame com as colunas desejadas\n",
    "        df_filtered = pd.DataFrame({\n",
    "            'id': df_fruits['id'],\n",
    "            'name': df_fruits['name'],\n",
    "            'description': df_fruits['description'],\n",
    "            'known_as': df_fruits['roman_name'],\n",
    "            'type': df_fruits['type'],\n",
    "            'fruit_image': df_fruits['filename']\n",
    "        })\n",
    "        # Verificar e criar o diretório de saída, se necessário\n",
    "        os.makedirs(os.path.dirname(filtered_path), exist_ok=True)\n",
    "        # Salvar o DataFrame filtrado em Parquet\n",
    "        df_filtered.to_parquet(filtered_path, engine=\"pyarrow\", index=False)\n",
    "        logging.info(f\"Arquivo salvo com sucesso em '{filtered_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar os dados: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_crews_data(raw_path, filtered_path):\n",
    "    try:\n",
    "        # Ler o arquivo Parquet\n",
    "        df_crews = pd.read_parquet(raw_path, engine='pyarrow')\n",
    "        # Verificar se o DataFrame tem dados\n",
    "        if df_crews.empty:\n",
    "            raise ValueError(\"O arquivo Parquet não contém dados.\")\n",
    "        # Criar um novo DataFrame com as colunas desejadas\n",
    "        df_filtered = pd.DataFrame({\n",
    "            'id': df_crews['id'],\n",
    "            'name': df_crews['name'],\n",
    "            'status': df_crews['status'],\n",
    "            'crewmate_number': df_crews['number'],\n",
    "            'is_yonko': df_crews['is_yonko']\n",
    "        })\n",
    "        # Verificar e criar o diretório de saída, se necessário\n",
    "        os.makedirs(os.path.dirname(filtered_path), exist_ok=True)\n",
    "        # Salvar o DataFrame filtrado em Parquet\n",
    "        df_filtered.to_parquet(filtered_path, engine=\"pyarrow\", index=False)\n",
    "        logging.info(f\"Arquivo salvo com sucesso em '{filtered_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar os dados: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para tratar os dados de personagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para limpar e converter para int\n",
    "def clean_and_convert_number(column):\n",
    "    # Verifica se a coluna é do tipo string antes de aplicar .str\n",
    "    if column.dtype == 'object':\n",
    "        # Remove caracteres não numéricos\n",
    "        column = column.str.replace(r'\\D', '', regex=True)\n",
    "    #  Substitui valores vazios por -1 e converte para inteiro\n",
    "    return column.fillna(-1).replace(\"\", -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para traduzir\n",
    "def french_to_english(texto):\n",
    "    if texto is None or pd.isna(texto):  # Verifica se o texto é nulo ou vazio\n",
    "        return texto  # Retorna o valor original se for nulo\n",
    "    try:\n",
    "        return translator.translate(texto)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao traduzir '{texto}': {e}\")\n",
    "        return texto  # Retorna o texto original em caso de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_characters_data(filtered_path, normalized_path):\n",
    "    try:\n",
    "        df_normalized = pd.read_parquet(filtered_path, engine='pyarrow')\n",
    "        # Colocar os valores das colunas em caixa baixa\n",
    "        columns_to_lower = [\"name\", \"job\", \"status\"]\n",
    "        df_normalized[columns_to_lower] = df_normalized[columns_to_lower].apply(lambda col: col.str.lower())\n",
    "        # Aplicando a função de limpeza e conversão para as colunas desejadas\n",
    "        columns_to_convert = [\"size\", \"age\", \"bounty\", \"crew_id\", \"fruit_id\"]\n",
    "        df_normalized[columns_to_convert] = df_normalized[columns_to_convert].apply(clean_and_convert_number)\n",
    "        # Substituir valores None ou em branco por \"unknown\" em todas as colunas\n",
    "        columns_to_change = [\"job\", \"status\"]\n",
    "        for column in columns_to_change:\n",
    "            df_normalized[column] = df_normalized[column].replace(\"\", None).fillna(\"unknown\")\n",
    "\n",
    "        # Verificar e criar o diretório de saída, se necessário\n",
    "        os.makedirs(os.path.dirname(normalized_path), exist_ok=True)\n",
    "        # Salvar o DataFrame filtrado em Parquet\n",
    "        df_normalized.to_parquet(normalized_path, engine=\"pyarrow\", index=False)\n",
    "        logging.info(f\"Arquivo salvo com sucesso em '{normalized_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar os dados: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fruits_data(filtered_path, normalized_path):\n",
    "    try:\n",
    "        df_normalized = pd.read_parquet(filtered_path, engine='pyarrow')\n",
    "        # Colocar os valores das colunas em caixa baixa\n",
    "        columns_to_lower = ['name', 'description', 'known_as', 'type']\n",
    "        df_normalized[columns_to_lower] = df_normalized[columns_to_lower].apply(lambda col: col.str.lower())\n",
    "        # Substituir onde não possui imagem por \"não disponível\"\n",
    "        df_normalized[\"fruit_image\"] = df_normalized[\"fruit_image\"].replace(\"https://images.api-onepiece.com/fruits/\", \"not available\")\n",
    "        # Manter apenas o texto antes da primeira vírgula\n",
    "        df_normalized[\"known_as\"] = df_normalized[\"known_as\"].str.split(\",\", n=1).str[0]\n",
    "        # Traduzir os textos em frances para ingles\n",
    "        columns_to_translate = ['name', 'type']\n",
    "        for column in columns_to_translate:\n",
    "            df_normalized[column] = df_normalized[column].apply(french_to_english)\n",
    "\n",
    "        # Verificar e criar o diretório de saída, se necessário\n",
    "        os.makedirs(os.path.dirname(normalized_path), exist_ok=True)\n",
    "        # Salvar o DataFrame filtrado em Parquet\n",
    "        df_normalized.to_parquet(normalized_path, engine=\"pyarrow\", index=False)\n",
    "        logging.info(f\"Arquivo salvo com sucesso em '{normalized_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar os dados: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_crews_data(filtered_path, normalized_path):\n",
    "    try:\n",
    "        df_normalized = pd.read_parquet(filtered_path, engine='pyarrow')\n",
    "        # Colocar os valores das colunas em caixa baixa\n",
    "        columns_to_lower = ['name', 'status']\n",
    "        df_normalized[columns_to_lower] = df_normalized[columns_to_lower].apply(lambda col: col.str.lower())\n",
    "        # Aplicando a função de limpeza e conversão para as colunas desejadas\n",
    "        columns_to_convert = [\"crewmate_number\"]\n",
    "        df_normalized[columns_to_convert] = df_normalized[columns_to_convert].apply(clean_and_convert_number)\n",
    "        # Dicionário de substituições\n",
    "        substituicoes = {\n",
    "            \"assets\": \"active\",\n",
    "            \"dissolved\": \"dissolved\",\n",
    "            \"unknown\": \"unknown\",\n",
    "            \"inactive\": \"inactive\",\n",
    "            \"arr�t�\": \"arrested\",\n",
    "            \"actif\": \"active\",\n",
    "            \"inconnu\": \"unknown\",\n",
    "            \"inactif\": \"inactive\",\n",
    "            None: \"unknown\",\n",
    "        }\n",
    "        # Substituir os valores da coluna 'status'\n",
    "        df_normalized[\"status\"] = df_normalized[\"status\"].replace(substituicoes)\n",
    "        # Traduzir a coluna\n",
    "        df_normalized[\"name\"] = df_normalized[\"name\"].apply(french_to_english)\n",
    "    \n",
    "        # Verificar e criar o diretório de saída, se necessário\n",
    "        os.makedirs(os.path.dirname(normalized_path), exist_ok=True)\n",
    "        # Salvar o DataFrame filtrado em Parquet\n",
    "        df_normalized.to_parquet(normalized_path, engine=\"pyarrow\", index=False)\n",
    "        logging.info(f\"Arquivo salvo com sucesso em '{normalized_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar os dados: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para processar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(config_dados):\n",
    "    # Percorrendo os valores de config_dados\n",
    "    for config in config_dados:\n",
    "        name = config['name']\n",
    "        api_url = config.get('api_url')\n",
    "        raw_path = config['raw_path']\n",
    "        filtered_path = config['filtered_path']\n",
    "        processing_filtered_function = config.get('filter_function')\n",
    "        normalized_path = config['normalized_path']\n",
    "        processing_normalize_function = config.get('normalize_function')\n",
    "\n",
    "        logging.info(f\"Processando {name}...\")\n",
    "\n",
    "        # Buscar os dados brutos\n",
    "        try:\n",
    "            fetch_raw_data(name, raw_path, api_url)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao buscar dados brutos de {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if processing_filtered_function:\n",
    "            try:\n",
    "                processing_filtered_function(raw_path, filtered_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao filtrar dados de {name}: {e}\")\n",
    "        else:\n",
    "            logging.error(f\"Nenhuma função definida para filtrar {name}.\")\n",
    "\n",
    "        if processing_normalize_function:\n",
    "            try:\n",
    "                processing_normalize_function(filtered_path, normalized_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao normalizar dados de {name}: {e}\")\n",
    "        else:\n",
    "            logging.error(f\"Nenhuma função definida para normalizar {name}.\")\n",
    "\n",
    "        logging.info(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dados = [\n",
    "    {\n",
    "        'name': 'personagens',\n",
    "        'api_url': 'https://api.api-onepiece.com/v2/characters/en',\n",
    "        'raw_path': 'raw_parquet/raw_characters.parquet',\n",
    "        'filtered_path': 'filtered_parquet/filtered_characters.parquet',\n",
    "        'filter_function': filter_characters_data,\n",
    "        'normalized_path': 'normalized_parquet/normalized_characters.parquet',\n",
    "        'normalize_function': normalize_characters_data\n",
    "    },\n",
    "    {\n",
    "        'name': 'frutas',\n",
    "        'api_url': 'https://api.api-onepiece.com/v2/fruits/en',\n",
    "        'raw_path': 'raw_parquet/raw_fruits.parquet',\n",
    "        'filtered_path': 'filtered_parquet/filtered_fruits.parquet',\n",
    "        'filter_function': filter_fruits_data,\n",
    "        'normalized_path': 'normalized_parquet/normalized_fruits.parquet',\n",
    "        'normalize_function': normalize_fruits_data\n",
    "    },\n",
    "    {\n",
    "        'name': 'tripulações',\n",
    "        'api_url': 'https://api.api-onepiece.com/v2/crews/en',\n",
    "        'raw_path': 'raw_parquet/raw_crews.parquet',\n",
    "        'filtered_path': 'filtered_parquet/filtered_crews.parquet',\n",
    "        'filter_function': filter_crews_data,\n",
    "        'normalized_path': 'normalized_parquet/normalized_crews.parquet',\n",
    "        'normalize_function': normalize_crews_data\n",
    "    }\n",
    "]\n",
    "\n",
    "process_data(config_dados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
